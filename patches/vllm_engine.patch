--- a/openrlhf/trainer/ray/vllm_engine.py
+++ b/openrlhf/trainer/ray/vllm_engine.py
@@ -116,6 +116,31 @@
             args=(name, dtype, shape, empty_cache),
         )

+    async def update_weight_from_ref(self, name, dtype, shape, weight_ref_bytes, empty_cache=False):
+        """Update a single weight from a Ray object store reference.
+
+        Dispatches to workers via collective_rpc for proper TP handling.
+        """
+        return await self.llm.collective_rpc(
+            "update_weight_from_ray_ref",
+            args=(name, dtype, shape, weight_ref_bytes, empty_cache),
+        )
+
+    async def apply_lora_update(self, lora_state, scaling):
+        """Apply LoRA adapter weight deltas to the base model.
+
+        Converts tensors to (shape, dtype, list) tuples for msgspec
+        serialization through collective_rpc. Workers reconstruct tensors.
+        """
+        import torch
+
+        serializable = {}
+        for name, tensor in lora_state.items():
+            if isinstance(tensor, torch.Tensor):
+                serializable[name] = (list(tensor.shape), str(tensor.dtype), tensor.tolist())
+            else:
+                serializable[name] = tensor
+        return await self.llm.collective_rpc(
+            "apply_lora_delta",
+            args=(serializable, scaling),
+        )
+
     async def update_weight_cuda_ipc(self, name, dtype, shape, ipc_handles, empty_cache=False):
         return await self.llm.collective_rpc(
             "update_weight_cuda_ipc",
